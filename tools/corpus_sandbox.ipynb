{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dda8e7a5",
   "metadata": {},
   "source": [
    "## Реализация поискового движка и обратного индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f411a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import razdel\n",
    "import pymorphy3 as pm\n",
    "from functools import lru_cache\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from uuid import uuid4\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a84eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_text(et: ET):\n",
    "    text = et.text or \"\"\n",
    "    for child in et:\n",
    "        text += get_all_text(child)\n",
    "        text += (child.tail or \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae280446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lemmatizer:\n",
    "\n",
    "    morph = pm.MorphAnalyzer()\n",
    "\n",
    "    @classmethod\n",
    "    @lru_cache(123456789)\n",
    "    def lemmatize(cls, word:str) -> str:\n",
    "        return cls.morph.parse(word)[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec14ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_lemmas(sent: str, punc=set(punctuation)) -> list[str]:\n",
    "    tokens = [tok.text for tok in razdel.tokenize(sent)]\n",
    "    return [Lemmatizer.lemmatize(tok) for tok in tokens if tok not in punc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b53447a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorpusEntry:\n",
    "\n",
    "    def __init__(self, et: ET):\n",
    "\n",
    "        self.uuid = uuid4()\n",
    "        self.xml = et\n",
    "\n",
    "        self.tokens = Counter(\n",
    "            get_all_lemmas(\n",
    "                get_all_text(self.xml).strip()\n",
    "            )\n",
    "        )\n",
    "\n",
    "        lex_tokens = [c.text.lower() for c in self.xml.findall(\".//lex\")]\n",
    "        lex_lemmas = [Lemmatizer.lemmatize(c) for c in lex_tokens]\n",
    "\n",
    "        self.lex_tokens = Counter(lex_tokens)\n",
    "        self.lex_lemmas = Counter(lex_lemmas)\n",
    "\n",
    "        self.rate = min(\n",
    "            sum(\n",
    "                [\n",
    "                    int(c.attrib[\"rate\"])\n",
    "                    for c\n",
    "                    in self.xml.findall(\".//tox\")\n",
    "                ]\n",
    "            ),\n",
    "            10\n",
    "        )\n",
    "\n",
    "        self.responses = [c.attrib[\"response\"].replace(\" \", \"\").lower() for c in self.xml.findall(\".//tox\")]\n",
    "        self.tox_types = [c.attrib[\"type\"].replace(\" \", \"\").lower() for c in self.xml.findall(\".//tox\")]\n",
    "        self.phrase_types = [c.attrib[\"type\"].replace(\" \", \"\").lower() for c in self.xml.findall(\".//phrase\")]\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.uuid)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            self.__class__.__name__ + \":\\n\"\n",
    "            + ET.tostring(self.xml, encoding=\"utf8\").decode(\"utf-8\") + \"\\n\"\n",
    "            + str(self.tokens) + \"\\n\"\n",
    "            + str(self.lex_tokens) + \"\\n\"\n",
    "            + str(self.lex_lemmas) + \"\\n\"\n",
    "            + \"rate=\" + str(self.rate) + \"\\n\"\n",
    "            + str(self.responses) + \"\\n\"\n",
    "            + str(self.tox_types) + \"\\n\"\n",
    "            + str(self.phrase_types)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71bb036",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchParams:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        query=\"\",\n",
    "        rate_start=0,\n",
    "        rate_end=10,\n",
    "        responses=[],\n",
    "        tox_types=[],\n",
    "        phrase_types = []\n",
    "    ):\n",
    "        self.query = query\n",
    "        self.rate_start = rate_start\n",
    "        self.rate_end = rate_end\n",
    "        self.responses = responses\n",
    "        self.tox_types = tox_types\n",
    "        self.phrase_types = phrase_types\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({self.query}, {self.rate_start}-{self.rate_end}, {self.responses}, {self.tox_types}, {self.phrase_types})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf22871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "\n",
    "    def __init__(self, path: str):\n",
    "\n",
    "        self.entries: dict[int, CorpusEntry] = dict()\n",
    "        self.lemma_index       = dict()\n",
    "        self.rate_index        = dict()\n",
    "        self.response_index    = dict()\n",
    "        self.tox_type_index    = dict()\n",
    "        self.phrase_type_index = dict()\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "            xml_data = file.read()\n",
    "\n",
    "        data = ET.fromstring(xml_data)\n",
    "\n",
    "        for text in data:\n",
    "            self.append(text)\n",
    "\n",
    "        self.build_index()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.entries[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def append(self, et):\n",
    "        self.entries[len(self)] = CorpusEntry(et)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}({len(self)} entries)\"\n",
    "\n",
    "    def build_index(self):\n",
    "\n",
    "        for i, entry in self.entries.items():\n",
    "\n",
    "            for token in entry.tokens:\n",
    "                self.lemma_index[token] = self.lemma_index.get(token, set()) | {i}\n",
    "\n",
    "            self.rate_index[entry.rate] = self.rate_index.get(entry.rate, set()) | {i}\n",
    "\n",
    "            for response in entry.responses:\n",
    "                self.response_index[response] = self.response_index.get(response, set()) | {i}\n",
    "                if \":\" in response:\n",
    "                    response = response.split(\":\", maxsplit=1)[0]\n",
    "                    self.response_index[response] = self.response_index.get(response, set()) | {i}\n",
    "\n",
    "            for tox_type in entry.tox_types:\n",
    "                self.tox_type_index[tox_type] = self.tox_type_index.get(tox_type, set()) | {i}\n",
    "                if \":\" in tox_type:\n",
    "                    tox_type = tox_type.split(\":\", maxsplit=1)[0]\n",
    "                    self.tox_type_index[tox_type] = self.tox_type_index.get(tox_type, set()) | {i}\n",
    "\n",
    "            for phrase_type in entry.phrase_types:\n",
    "                self.phrase_type_index[phrase_type] = self.phrase_type_index.get(phrase_type, set()) | {i}\n",
    "\n",
    "    def search(self, params:SearchParams) -> list[int]:\n",
    "\n",
    "        # Множество записей с подходящими леммами\n",
    "        sets = [\n",
    "            self.lemma_index.get(token, set())\n",
    "            for token\n",
    "            in get_all_lemmas(params.query)\n",
    "        ]\n",
    "\n",
    "        # Множество записей с подходящими rate\n",
    "        sets.append(\n",
    "            reduce(\n",
    "                lambda s1, s2: s1 | s2,\n",
    "                [\n",
    "                    self.rate_index.get(id_, set())\n",
    "                    for id_\n",
    "                    in range(params.rate_start, params.rate_end + 1)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Множество записей с подходящими responses\n",
    "        if params.responses:\n",
    "            sets.append(\n",
    "                reduce(\n",
    "                    lambda s1, s2: s1 | s2,\n",
    "                    [\n",
    "                        self.response_index.get(response, set())\n",
    "                        for response\n",
    "                        in params.responses\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Множество записей с подходящими tox_types\n",
    "        if params.tox_types:\n",
    "            sets.append(\n",
    "                reduce(\n",
    "                    lambda s1, s2: s1 | s2,\n",
    "                    [\n",
    "                        self.tox_type_index.get(tox_type, set())\n",
    "                        for tox_type\n",
    "                        in params.tox_types\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Множество записей с подходящими phrase_types\n",
    "        if params.phrase_types:\n",
    "            sets.append(\n",
    "                reduce(\n",
    "                    lambda s1, s2: s1 | s2,\n",
    "                    [\n",
    "                        self.phrase_type_index.get(phrase_type, set())\n",
    "                        for phrase_type\n",
    "                        in params.phrase_types\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return reduce(lambda s1, s2: s1 & s2, sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a68017",
   "metadata": {},
   "source": [
    "## Примеры запросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6edcf64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path.cwd() / r\"..\" / r\"webapp\" / r\"data\" / r\"all_toxic_comments.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c297bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e5053ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['general_insult',\n",
       " 'profanity',\n",
       " 'harassment',\n",
       " 'hate_speech:lgbtq*',\n",
       " 'hate_speech',\n",
       " 'hate_speech:nationality',\n",
       " 'hate_speech:gender',\n",
       " 'threat',\n",
       " 'hate_speech:religion',\n",
       " 'hate_speech:race']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(corpus.tox_type_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d408f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тут Маваши не из денег не стал стричься, а из за того что парикмахер чурка)\n",
      "Я думал там между машин ее зажало.А это очередная ТП мама меня фура убила.Бабы,ну что вы за существа?Не все.Но очень многие\n",
      "Это они чтоб не травмировать скрепных мужиков, которые падают в обморок, увидев в ванной пачку прокладок жены.\n",
      "Шах и мат губошлёпки\n",
      "как же любят чуркобесы свои автопортреты всюду лепить...\n",
      "Мощно инцел бомбит 😂\n",
      "Ну у вас там один хер нет никакой экологии, какая назуй разница будем посмотреть\n",
      "Ради чего нужно вешать себе эту швабру на шею, за такие деньги? Проститутки выходят куда дешевле. Их не нужно содержать, можешь делать с нею что воображение пожелает. Платишь только за то, что покупаешь. И главное - менять можно как перчатки 🤣🤣🤣.\n",
      "Вагинокапитализм оказывется реальностью.\n",
      "Изменила мужу шлюха. Всё просто.\n",
      "опять эти надежды инцелов и одиноких скуфов, что если у женщины появился ребенок, то она станет всеядной и \"снизит планку\" до вас.\n",
      "Страдай, изврощенец. Однако раньше рядом с хрюканом получше были тянки. А сейчас недотрапы колхозные и шизанутые.\n",
      "Добро пожаловать в 2025, рыночек вагины в космосе. Принцеждалки ждут чедика, попутно рушат жизни нормальных мужчин, подсаживаю на алики и забирая недвижимость. Решение есть, правильные тян есть в Филиппинах, Вьетнаме, Африке. Пора завозить от туда\n",
      "Жалкие сельдеоправдания.\n",
      "Я не сельдь,  дебилушка\n",
      "Фу, пиздец. Двачую. Я туда даже хуй засунуть брезгую\n",
      "Видимо, ХОЗЯЮШКА, которая это сварганила, работает посудомойщицей в столовке и из объедков, которые к тарелкам наприлипали, сука тупая, слепила это чудо-объедение. Это каким отбитым жлобом надо быть, чтобы такое добровольно есть?\n",
      "\\\"не парься, я на таблетках (а я - не на таблетках) \\\"\n",
      "трахать все равно некого, феминистки задрали цену на секс, а без резины потом засудят за износ\n",
      "Так поэтому и говорят, что хуй не суй в ебанутых! С:\n",
      "Мало ли что... но многие не следуют этому.\n",
      "Когда орда явилась в дом, и средь чумы кровавый пир, Сперва насилуют детей, потом страну, потом весь мир.\n",
      "Вот жопа гореть будет у баб, которые мечтают залететь без согласия мужика. У меня столько знакомых парней, которых фактически обманом сделали отцами ради выгодной партии.\n",
      "С тех пор научились доставать кишку из козы перед сексом. Но на Кавказе всё ещё есть ценители старых обычаев.\n",
      "Очередная чурка на старом рыдване.\n",
      "Шокер или балончик. Зачем с животными вообще разговаривать? Вы же с агрессивной собакой беседы не ведете\n",
      "Хвостики просто поиграть хотели, в поедание нигера.\n",
      "Вам, геям, лишь бы слово вставить\n",
      "Архитектор? С чуркобесами разговаривает?)) Нуну)))\n",
      "Это не для феминисток радость, а для МДшников, у которых ор выше гор, что бабы рожают из-за алиментов.\n",
      "Теперь у них есть шанс яйца в узелок завязать так, чтоб ни одна коварная баба не залетела.\n",
      "Не боись черножопый, мы не только не вымрем, а еще на твоих похоронах и твоих потомков гулять и радоваться будем) таких как ты предсказателей, которые давно гниют в небытие, были вагон и меленькая тележка. Лай дальше)\n",
      "Сдаëтся мне, эта мразота просто кидает своих не слишком умных соотечественников!\n",
      "Наконец то. Защита от хитровы.. и не очень умных баб\n",
      "Не понял. А почему бездельничают, не льют туда бензин?!\n",
      "Давно пора. Теперь-то тупые дырки не смогут попытаться привязать к себе, или просто подставить мужика под алименты, залетев от него. Если мужик сам не тупой, конечно.\n",
      "Тупые дырки минусят)))\n",
      "Днк тест начнёт с новой силой рвать пердаки ушлым бабенкам\n",
      "Гей-клуб Голубая устрица проводит набор новых членов и жоп.\n",
      "Тут я с автором соглашусь... Женщины в своём развитии остались на уровне каменного века... Они думаю что мышцы и навыки клоуна делают преимущество для самца. С другой стороны это и в общении приятно.. Но! Потом понимают что деньги в основном это ботаны.\n",
      "А у нас в Казахстане они дороги делают. Так вот делают они это хуево. Но виоимо заносят кому надо, кормят кого надо. Ничего им за это не делают\n",
      "Если армянин назвал тебя другом - хочет наебать. Если назвал братом - уже наебал.\n",
      "использует как приемник спермы, ему по вере нельзя в салфетку\n",
      "бывшЕй, чурка малограмотный\n",
      "Лет 10-15 назад у нас такое про мигрантов в гейропе показывали. Типа, замените какой там пиздец! Ужоснах! При этом то же самое происходило и у нас.\n",
      "Деморежим закончился Гони нахер. Она сломалась. И радуйся, что это выплыло до свадьбы и заведения личинок. Ищи другую.\n",
      "Почему все эти достойные люди никогда не выступают с осуждением поступков своих дегенератов единоверцев?\n",
      "Я тоже знаю много кавказцев - они все такие, даже при союзе понаехавшие- все мразота , в той , или иной степени.\n",
      "Не бывает хороших хачей\n",
      "Это тебя пиздосестрия минусует за то, что посмел такую аналогию обломать)\n",
      "Обычная отмазка не бесхозной женщины бляди при измене 😁😁😁\n",
      "Как в песне группы Ленинград \"менеджер\"\n",
      "всё бабы твари🙈\n",
      "Хачик расфантазировался и пошёл драть овцу.\n",
      "хммм.. отзывы. Не захотела знакомиться с Мухамаджоном который писку просит ебать, лови в отзыв что ты шелуха, и мать твоя шелуха, и отец твой тоже.\n",
      "ЮНЦОВ, ЮНЦОВ, ОПЯТЬ ЮНЦОВ... ДА КАКИЕ НА ХРЕН ЮНЦЫ??? АБУ-БАНДИТЫ, ИШАКИ, ЧЕРТИ - ВОТ КАК ИХ НУЖНО НАЗЫВАТЬ !!!!!!! ЮНЦЫ БЛИН...\n",
      "Каблук ебаный. (Забыл добавить)\n",
      "Ох, ты. Ты только что использовал такой способ отмазки меркантильнях сук, которото я прежде не видел.\n",
      "Пхпххахахахэахахаххахахахахаххахахахахах госпади, какой же ты сумасшедший неликвид надеюсь, все мужчины уклонились от тебя.\n",
      "Ей ничего не должны, буевально сотни миллионов женщин если не миллиардов готовы глаз отдать, что бы попасть на ее месте.\n",
      "Твои влажные фантазии как тебе платят, за твою старую тушку восхиьиетльны\n",
      "У бородатых обезьянок уже бомбануло?\n",
      "Хач-апокалипсис. Раковая опухоль Россиюшки.\n",
      "Ой бля,очередное обиженное \\\"Бабы ничего не делают, ПРОСТО дома с детьми сидят\". 😮‍💨\n",
      "Бабы пидоры, что ещё тут сказать 😆\n",
      "Ох, как я согласен с ТС, такое кол-во хабалистых куриц набежало в том посте😂\n",
      "Что и говорить: современные бабы - пидоры!\n",
      "Во всех новостях восемь из десяти очередная бородая рожа чурбанского скота. Такое ощущение, что кроме них уже реально никто закон не нарушает.\n",
      "Просто бляди. Не больше не меньше. Таких историй каждая вторая.\n",
      "Как боженька молвил. Бабцы так то прихуели. Хоть и далеко не все.\n",
      "У местных фебанашек не срабатывает, что любой быт ты для себя также делаешь.\n",
      "Типичный черножопый мышебрат.Молчал бы в тряпочку,легко в правоохренительные органы устроился.Такие там нужны.\n",
      "Подкаблучник так и не понял, что не важно работает женщина или нет, но все равно главная в доме она, а его место у параши.)))\n",
      "Просто рсп и жирухи думают что они нужны\n",
      "И снова черножопые петухи, считающие себя мужчинами.\n",
      "А так ты больная на голову свихнувшаяся на почве отсутствия регулярного секса 🤣\n",
      "Яжемать с весенним обострением детектед. РСП наверняка, к тому же.\n",
      "Вся суть чурок, когда прижмëт, сразу Слава роду русскому\n",
      "Млять, какие же они омерзительные и интеллектуально-убогие...\n",
      "Ничоси какая порванка. Не трясись:)\n",
      "Слышь, морда корейская, ты наших женщин не обижай. Нихуя они не спрашивают такого, если ты только не дрочила с сайта олени.рф. они любить умеют, искренне и с полной отдачей\n",
      "всраньку леху пыню влада сисяна затравили, а эту шлюху нет. Почему? она тян.\n",
      "ты совсем дурачок, хохол? что такое по твоему построенная новая дорога?\n",
      "Даже в моей 17к (!!!) мухосрани в сибири есть чеченцы и даги. Пару лет назад одного русачка пришили за то что жену чеченца ебал. Пекут по-тихому свою шаурму, обувь ремонтируют, на стройках шабашат Наташ поябывают, в диаспоры объединяются, чтобы рюсню набутыливать.\n"
     ]
    }
   ],
   "source": [
    "for id_ in corpus.search(\n",
    "    SearchParams(\n",
    "        rate_start=5,\n",
    "        rate_end=6,\n",
    "        tox_types=[\"hate_speech\"],\n",
    "    )\n",
    "):\n",
    "    print(get_all_text(corpus[id_].xml).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761943f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
